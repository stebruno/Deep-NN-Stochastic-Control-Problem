{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqKb85TnnbH8",
    "outputId": "12312f1f-09b0-4f67-8d07-ae9d671566b6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "import random\n",
    "random.seed(1000)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from time import time\n",
    "\n",
    "# Set data type\n",
    "#DTYPE='float32'\n",
    "DTYPE='float64'\n",
    "tf.keras.backend.set_floatx(DTYPE)\n",
    "print('TensorFlow version used: {}'.format(tf.__version__))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsjrf2Kmngiw"
   },
   "outputs": [],
   "source": [
    "# Cost of non-smooth control\n",
    "eps = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKrRlqy2nlai"
   },
   "outputs": [],
   "source": [
    "def noise(num_sample, N, k, dt):\n",
    "    dW = np.random.normal(loc=0.0, scale=np.sqrt(dt), size=(num_sample, N,k)).astype(DTYPE) \n",
    "    return dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylhL7K6nnqko"
   },
   "source": [
    "The state variable $(X_t)_{t \\in \\{0,1,\\dots, N-1 \\}} =(B_t, P_t)_{t \\in \\{0,1,\\dots, N-1 \\}}$ where $B_t$ is the battery level and $P_t$ is the (spot) market price. We can assume that $P_t \\in \\mathbb{R}^d$ and $P_t^0$ is the current price. In the following cell below, we simulate the price process using an Ornstein-Uhlenbeck process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLBtnrB_nn1X"
   },
   "outputs": [],
   "source": [
    "num_days_price = 7\n",
    "\n",
    "# Final time\n",
    "T = num_days_price\n",
    "\n",
    "# Dimension of the state space\n",
    "dim = 2\n",
    "\n",
    "\n",
    "# Steps per day\n",
    "steps_per_day = 48\n",
    "\n",
    "# Number of time steps\n",
    "N = num_days_price*steps_per_day # Transforms in hours 7*24=168\n",
    "\n",
    "# Derive time step size and t_space\n",
    "dt = T/N\n",
    "t_space = np.linspace(0., T, N + 1)\n",
    "\n",
    "pi=math.pi\n",
    "# f= lambda t : np.cos(2.*pi*t)\n",
    "#f = lambda t : 5. * np.cos(2.*pi*t) + 16. + 2. * np.cos(6.*pi*t + 0.3) - 1. * np.cos(24*pi*t-0.4)\n",
    "f = lambda t : (1. * np.cos(2.*pi*t) + 1. + 0.5 * np.cos(6.*pi*t + 0.3) )*0.25\n",
    "\n",
    "# Define a price shift. Won't be calculated in optimised profit, but included for plots.\n",
    "price_shift = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "oMbjDVItnwSp",
    "outputId": "8d920efc-aa91-4164-9a68-f50f1714cec9"
   },
   "outputs": [],
   "source": [
    "# p0_vec = np.array([0.1, -0.2, -0.4, 0.5, 0.7])\n",
    "# sigmaOU_vec = np.array([6., 20.0, 3., 10., 20.])\n",
    "# thetaOU_vec = np.array([10., 1.2, 2.4, 5., 0.3])\n",
    "\n",
    "p0_vec = np.array([-0.1, +0.2,])\n",
    "sigmaOU_vec = np.array([6., 12.0])\n",
    "thetaOU_vec = np.array([10., 1.2])\n",
    "\n",
    "\n",
    "k = np.size(p0_vec)\n",
    "p0_vec = np.reshape(p0_vec,(k,1))\n",
    "muOU_vec = np.zeros(k)\n",
    "\n",
    "num_sample = 100\n",
    "#num_sample = 10000\n",
    "#num_sample = 5000\n",
    "\n",
    "def simOU(p0_vec,tV,muOU_vec,sigmaOU_vec,thetaOU_vec,dW):\n",
    "    X = np.zeros((np.shape(dW)[0],np.size(p0_vec),np.size(tV)))\n",
    "    for j in range(np.size(p0_vec)):\n",
    "        W = sigmaOU_vec[j]*dW[:,:,j]                \n",
    "        X[:,j,0] = p0_vec[j,0]\n",
    "        for i in range(len(tV)-1):\n",
    "            X[:,j,i+1] = X[:,j,i]+thetaOU_vec[j]*(muOU_vec[j]-X[:,j,i])*(tV[i+1]-tV[i]) + np.sqrt(tV[i+1]-tV[i])*W[:,i]\n",
    "    return X\n",
    "\n",
    "\n",
    "price_vec = simOU(p0_vec,t_space,muOU_vec,sigmaOU_vec,thetaOU_vec,noise(num_sample, N, k, dt)) # (5, 101) 5 days\n",
    "sum_price_vec_days= np.sum(price_vec, axis=1) \n",
    "#sum_price_vec_days=sum_price_vec_days.reshape(1,101)\n",
    "# Forward curve\n",
    "price_curve = f(t_space) + sum_price_vec_days+price_shift\n",
    "plt.plot(t_space,price_curve[0],t_space,f(t_space)+price_shift);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bscTwqUroF_5",
    "outputId": "d639e53f-79dd-4c93-e15d-8353ba378ac8"
   },
   "outputs": [],
   "source": [
    "# Tidal component semi-diurnal table\n",
    "periods = np.array([12.4206012, 12., 12.65834751, 23.93447213, 6.210300601, 25.81933871, 4.140200401, 8.177140247, 6., 6.269173724]) \n",
    "# M2 S2 N2 (semi-diurnal), K1 (diurnal), M4 (Short period) O1 (diurnal) M6 (short period) MK3 (short period) S4 (short period) MN4 (short period)\n",
    "# In hours, by NOAA ranking\n",
    "\n",
    "# Amplitudes (half of peak-to-peak) amplitude are given below\n",
    "ME = [268.7, 42.0, 54.3, 15.6, 6.0, 11.9, 5.1, 0., 0., 2.3] # Amplitudes for  Eastport, Maine (ME)\n",
    "# Here the last to second and the previous are set to zero (missing values in the table?)\n",
    "\n",
    "AK = [97.3,32.5,20.1,39.8, 0.9,25.9,1.0,0.5,0.0,0.3] #Amplitudes for  Kodiak, Alaska (AK)\n",
    "#  Here the last to second is set to zero (missing value in the table?)\n",
    "\n",
    "amp = 0.1*np.array(ME)\n",
    "no_terms = 8\n",
    "phase_shift = rng.uniform(0.,1.,no_terms)*periods[:no_terms]\n",
    "\n",
    "# print(phase_shift)\n",
    "\n",
    "cutoff = 0.6\n",
    "flow_max = 20.**(1/3)\n",
    "\n",
    "#OLD\n",
    "#days = 7\n",
    "#N = 10000\n",
    "#T = 24*days\n",
    "#t = np.linspace(0,T,N)\n",
    "\n",
    "num_days_power = 7    # This is the same as for the num_days_price\n",
    "N_power = num_days_power*steps_per_day # This is the same as N for the price\n",
    "t = np.linspace(0., num_days_power, N_power+1)\n",
    "\n",
    "# plt.plot(t,np.dot(amp[:no_terms],np.sin(2*np.pi*(np.tile(t*24,(no_terms,1)).T-phase_shift[:no_terms])/periods[:no_terms]).T))\n",
    "# plt.figure()\n",
    "# plt.plot(t,np.dot(amp[:no_terms]/periods[:no_terms],np.cos(2*np.pi*(np.tile(t*24,(no_terms,1)).T-phase_shift[:no_terms])/periods[:no_terms]).T))\n",
    "flow = np.dot(amp[:no_terms]/periods[:no_terms],np.cos(2*np.pi*(np.tile(t*24,(no_terms,1)).T-phase_shift[:no_terms])/periods[:no_terms]).T)\n",
    "#dG_t =flow\n",
    "dG_t =(np.minimum(np.abs(flow),flow_max)*(np.abs(flow)>cutoff))**3\n",
    "#dG_t =np.abs(flow)\n",
    "# plt.figure()\n",
    "plt.plot(t,dG_t)\n",
    "plt.title(\"Tidal Energy Generation\");\n",
    "#plt.plot(t,np.abs(flow))\n",
    "\n",
    "\n",
    "#OLD\n",
    "#plt.plot(t/24,np.dot(amp[:no_terms],np.sin(2*np.pi*(np.tile(t,(no_terms,1)).T-phase_shift[:no_terms])/periods[:no_terms]).T))\n",
    "## np.tiles: Construct an array by repeating A the number of times given by reps.\n",
    "#plt.figure()\n",
    "#plt.plot(t/24,np.dot(amp[:no_terms]/periods[:no_terms],np.cos(2*np.pi*(np.tile(t,(no_terms,1)).T-phase_shift[:no_terms])/periods[:no_terms]).T))\n",
    "#flow = np.dot(amp[:no_terms]/periods[:no_terms],np.cos(2*np.pi*(np.tile(t,(no_terms,1)).T-phase_shift[:no_terms])/periods[:no_terms]).T)\n",
    "#plt.figure()\n",
    "#plt.plot(t/24,np.abs(flow)**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJs4aisutEYs"
   },
   "outputs": [],
   "source": [
    "class BSDEModel(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        # Call initializer of tf.keras.Model\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Initialize the control randomly\n",
    "        #control_0 = np.random.uniform(-1e-1, 1e-1, size=(1, dim)).astype(DTYPE)\n",
    "        control_0 = np.random.uniform(-1e-1, 1e-1, size=(1)).astype(DTYPE)    \n",
    "        self.control_0 = tf.Variable(control_0)\n",
    "        \n",
    "        # Create template of dense layer without bias and activation\n",
    "        _dense = lambda dim: tf.keras.layers.Dense(\n",
    "            units=dim, # number of nodes\n",
    "            activation=None,\n",
    "            use_bias=False)\n",
    "        \n",
    "        # Create template of batch normalization layer\n",
    "        _bn = lambda : tf.keras.layers.BatchNormalization(\n",
    "            momentum=.99,\n",
    "            epsilon=1e-6,\n",
    "            beta_initializer=tf.random_normal_initializer(0.0, stddev=0.1),\n",
    "            gamma_initializer=tf.random_uniform_initializer(0.1, 0.5))\n",
    "        \n",
    "        \n",
    "        # Initialize a list of networks approximating the control alpha_{t_i} at t_i\n",
    "        self.control_i = []\n",
    "        \n",
    "        # Loop over number of time steps\n",
    "        for j in range(N):\n",
    "            \n",
    "            # Batch normalization on dim-dimensional input\n",
    "            this_control = tf.keras.Sequential() # Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "            # Sequential() makes a list of all the layers you want to stack together. Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "            this_control.add(tf.keras.layers.Input(dim+j+1)) # tf.keras.Input() is used to instantiate a Keras tensor.\n",
    "            this_control.add(_bn())\n",
    "            \n",
    "            # Two hidden layers of type (Dense -> Batch Normalization -> ReLU)\n",
    "            for _ in range(2):\n",
    "                this_control.add(_dense(dim+10+j))\n",
    "                this_control.add(_bn())\n",
    "                this_control.add(tf.keras.layers.ReLU()) # adding layer\n",
    "                \n",
    "            # Dense layer followed by batch normalization for output\n",
    "            this_control.add(_dense(1))\n",
    "            this_control.add(_bn())\n",
    "            self.control_i.append(this_control)\n",
    "        \n",
    "        # The output of this class is a list of networks approximating the control alpha_{t_i} at t_i which is self.control_i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqZyi0S0vQ8H"
   },
   "source": [
    "Next, we define a function to draw multiple realizations of $\\tilde C_{N} \\approx u(T, X_T)$ by sweeping through the network. The intermediate values $\\{\\tilde C_{i}\\}_{i=0,\\ldots,N-1}$ are not stored.\n",
    "Note that we try to use the network to determine the amount of power at each stage that we store in the battery.\n",
    "\n",
    "We suppose that we generate power $g_n$ at time $n$, when our current battery has state $b_n$. Then we must choose $\\delta b_n := b_{n+1}-b_n$, so that the following all hold:\n",
    "\n",
    "\n",
    "*   $\\delta b_n \\in [-b_n, g_n]$, ie we only store energy generated by the turbine\n",
    "*   $\\delta b_n \\le \\bar{b} - b_n$ ie we cannot exceed the battery capacity.\n",
    "\n",
    "We can formulate this as: $\\delta b_n \\in [-b_n, \\min\\{g_n,(\\bar{b}-b_n)\\}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ev_LCGSDvMyP"
   },
   "outputs": [],
   "source": [
    "def simulate_Y(inp, model, full_output=False):\n",
    "    \"\"\" This function performs the forward sweep through the network.\n",
    "    Inputs:\n",
    "        inp - (price, dG_t, battery_0, max_battery)\n",
    "        model - model of neural network, contains\n",
    "            - control_0 - variable approximating the control alpha(0, x)\n",
    "            - control_i - list of NNs approximating the mapping: x -> alpha_{t_i}\n",
    "    \"\"\"\n",
    "    \n",
    "    price, dG_t, battery_0, max_battery = inp\n",
    "    num_sample = price.shape[0] # same dimension as X.shape[0] in DeepBSDE_Solver\n",
    "    \n",
    "    N = price.shape[1]-1\n",
    "    \n",
    "    p_scale = 100. # Scaling factor for price in calculations\n",
    "    \n",
    "    if full_output:\n",
    "        store_battery = np.zeros(N+1)\n",
    "        store_grid = np.zeros(N+1)\n",
    "        store_price = np.zeros(N+1)\n",
    "        store_cost = np.zeros(N+1)\n",
    "\n",
    "\n",
    "    #e_num_sample = tf.ones(shape=[num_sample, 1], dtype=DTYPE)      # TensorShape([10, 1])\n",
    "    e_num_sample = tf.ones(shape=[num_sample,1], dtype=DTYPE)       # TensorShape([10])\n",
    "    \n",
    "    # Old Output\n",
    "    out = 0.05*max_battery*e_num_sample\n",
    "    \n",
    "    # y = reward so far\n",
    "    y = tf.zeros(shape=[num_sample,1], dtype=DTYPE)        # TensorShape([10])\n",
    "\n",
    "    # Control alpha_{t0} approximation at t0\n",
    "    z = e_num_sample * model.control_0    # control_0.shape is (1, 100), z.shape is TensorShape([10, 100]).\n",
    "\n",
    "    # Battery State\n",
    "    battery_i = tf.ones(shape=[num_sample,1], dtype=DTYPE)  * battery_0     # battery_i.shape is (1, 100), battery_i.shape is TensorShape([10, 100]).   \n",
    "    #print(battery_i.shape)\n",
    "    \n",
    "    # Price process for the cost function. I still need to add to the inputs of simulate_Y\n",
    "    price = tf.convert_to_tensor(price, dtype=DTYPE)    # This produces TensorShape([10, 100])\n",
    "\n",
    "    # Power generation process. I still need to add to the inputs of simulate_Y\n",
    "    power = tf.ones(shape=[num_sample, 1], dtype=DTYPE)  * dG_t  # This produces TensorShape([10, 100])\n",
    "\n",
    "    if full_output:\n",
    "        #store_battery[0] = battery_i[0]\n",
    "        store_price[0] = price[0,0]\n",
    "\n",
    "    for i in range(N):\n",
    "        poww = tf.reshape(power[:,i],[num_sample,1])\n",
    "        pri = tf.reshape(price[:,i],[num_sample,1])\n",
    "        \n",
    "        # net battery flow is the amount we send from dG_t into the battery.\n",
    "        #   Note that this must be between -b_n and min(dG_n, max_b - b_n)\n",
    "        \n",
    "        mn = -battery_i\n",
    "        mx = tf.math.minimum(poww,(max_battery-battery_i))\n",
    "        \n",
    "        \n",
    "        # Select net battery change \\delta b_n as f(z)*(mx-mn)/2+ (mx+mn)/2, where\n",
    "        #.   f(z) -> [-1,1] is increasing, smooth.\n",
    "        net_battery = 2.*tf.math.atan(z)/(pi) * (mx-mn)/2. + (mx+mn)/2.\n",
    "        \n",
    "        battery_i = battery_i + net_battery\n",
    "\n",
    "        #display(price.shape)\n",
    "        eta2 = poww - net_battery  #  power[:,i] is TensorShape([10, 100]), while net_battery is TensorShape([10, 100]).\n",
    "        \n",
    "\n",
    "        # Compute new value cost value approximations at t_{i+1}. \n",
    "        y = y + pri * eta2 - eps * (eta2-out)**2  # y is a tensor with dimension TensorShape([10, 1])\n",
    "        #         y = y + pri * eta2 - poww * pri # y is a tensor with dimension TensorShape([10, 1])\n",
    "\n",
    "        out = eta2\n",
    "        \n",
    "        z =  tf.reshape(model.control_i[i](tf.concat([p_scale*price[:,:(i+1)],battery_i,out], axis=1)),[num_sample,1])\n",
    "        \n",
    "        if full_output:\n",
    "            store_battery[i] = battery_i[0]\n",
    "            store_price[i+1] = price[0,i+1]\n",
    "            store_grid[i] = poww[0] - net_battery[0]\n",
    "            store_cost[i] = y[0]\n",
    "\n",
    "\n",
    "    #display(z)\n",
    "    poww = tf.reshape(power[:,N],[num_sample,1])\n",
    "    pri = tf.reshape(price[:,N],[num_sample,1])\n",
    "    mn = -battery_i\n",
    "    mx = tf.math.minimum(poww,max_battery-battery_i)\n",
    "\n",
    "    # Select net battery change \\delta b_n as f(z)*(mx-mn)/2+ (mx+mn)/2, where\n",
    "    #.   f(z) -> [-1,1] is increasing, smooth.\n",
    "    net_battery = 2.*tf.math.atan(z)/(pi) * (mx-mn)/2. + (mx+mn)/2.\n",
    "    #     net_battery = tf.math.atan(z)/(pi) * max_battery + (max_battery/2 -battery_i)\n",
    "    battery_i = battery_i + net_battery\n",
    "\n",
    "    eta2 = poww - net_battery  #  power[:,i] is TensorShape([10, 100]), while net_battery is TensorShape([10, 100]).\n",
    "    \n",
    "\n",
    "    # Compute new value cost value approximations at t_{i+1}. \n",
    "#     y = y + pri * eta2 - poww * pri  # y is a tensor with dimension TensorShape([10, 1])\n",
    "    y = y + pri * eta2 - eps*(eta2-out)**2  # y is a tensor with dimension TensorShape([10, 1])\n",
    "\n",
    "\n",
    "    # Final step\n",
    "    eta3 = battery_i * 0.95 * pri # average future prices it should be tf.Variable()\n",
    "    y = y + eta3 \n",
    "\n",
    "    if full_output:\n",
    "        store_battery[-1] = battery_i[0]\n",
    "        store_grid[-1] = poww[0]-net_battery[0]\n",
    "        store_cost[-1] = y[0]\n",
    "        return y, store_battery, store_price, store_grid, store_cost\n",
    "    else:\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkhlwB5wvyFx"
   },
   "source": [
    "Through the application of this function, we may generate for each approximate state path $\\{\\tilde B_{i}\\}_{i=0,\\ldots,N}$ with corresponding Brownian motion $\\{ W_{t_i}^P \\}_{i=0,\\ldots,N}$ one realization of $\\tilde C_N$ given our unknown network parameters\n",
    "$$\n",
    "\\theta = \\left( \\theta_{\\alpha_1}, \\ldots \\theta_{\\alpha_{N-1}} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY9mebehv2W0"
   },
   "source": [
    "\n",
    "# 4. Evaluation of loss function\n",
    "\n",
    "In the next step, we define the loss function, i.e., the function to be minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VegKRlT1vuhW"
   },
   "outputs": [],
   "source": [
    "def loss_fn(inp, model):\n",
    "    \"\"\" This function computes the cost function.\n",
    "    Inputs:\n",
    "        inp - (dW_G, dW_P, simOU,dG_t, max_battery)\n",
    "        model - model of neural network containing C0, control_0, battery_0 and control_i.\n",
    "    \"\"\"\n",
    "\n",
    "    # Forward pass to compute value estimates\n",
    "    y_pred = simulate_Y(inp, model)\n",
    "            \n",
    "    loss = tf.reduce_mean(-y_pred)  # tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAq1xpKVv-ik"
   },
   "source": [
    "# 5. Computation of the gradient w.r.t. the network parameters $\\theta$\n",
    "\n",
    "The next step uses the automatic differentiation functionality of TensorFlow to compute the gradient of the loss function with respect to the unknowns $\\theta$, called trainable_variables in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nMp5xX8v_Th"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_grad(inp, model):\n",
    "    \"\"\" This function computes the gradient of the loss function w.r.t.\n",
    "    the trainable variables theta.\n",
    "    Inputs:\n",
    "        inp - (dW_G, dW_P, simOU,dG_t, max_battery)\n",
    "        model - model of neural network containing  C0, control_0, battery_0 and control_i.\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.GradientTape() as tape:      # Gradient Tape tracks the automatic differentiation that occurs in a Tensorflow model.\n",
    "        loss = loss_fn(inp, model)\n",
    "        \n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWnodbbowCKu"
   },
   "outputs": [],
   "source": [
    "# Set learning rate\n",
    "lr = 1e-2\n",
    "#lr = 1.\n",
    "\n",
    "# Choose optimizer for gradient descent step\n",
    "#optimizer = tf.keras.optimizers.Adam(lr, epsilon=1e-8)\n",
    "optimizer = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "# Initialize neural network architecture\n",
    "model = BSDEModel()\n",
    "\n",
    "# Initialize list containing history of losses\n",
    "history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pDkew4Ue4zv"
   },
   "source": [
    "Training without changing the maximum battery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwrNY5HzwFDX",
    "outputId": "14dcea92-f1fe-4fc0-a7be-05ff5d19a1a5"
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# num_epochs = 40000\n",
    "# num_epochs = 2000\n",
    "#Â num_epochs = 500\n",
    "num_epochs = 1000\n",
    "\n",
    "battery_0 = 0.\n",
    "max_battery = 100\n",
    "# p0_vec = np.reshape(p0_vec, (k,1))\n",
    "#p0_vec_new = p0_vec*np.ones((1,num_sample))\n",
    "#p0_vec = np.array([0.1, 0.2, 0.4, 0.5, 0.7])\n",
    "#p0_vec = np.reshape(p0_vec,(5,1))\n",
    "#k=np.size(p0_vec)\n",
    "\n",
    "# Initialize header of output\n",
    "print('  Iter          Loss          y   |   Time  Stepsize')\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    # Each epoch we draw a batch of random paths\n",
    "    #price = simOU(p0_vec,t_space,noise(num_sample, N, dt)) + cyclical(t_space,10.,0.3,0.5)\n",
    "    #price = (p0_vec_new,t_space,muOU_vec,sigmaOU_vec,thetaOU_vec,dW)\n",
    "    price_vec = simOU(p0_vec,t_space,muOU_vec,sigmaOU_vec,thetaOU_vec,noise(num_sample, N, k, dt))# (5, 101) 5 days\n",
    "    sum_price_vec_days= np.sum(price_vec, axis=1)\n",
    "    price_curve = f(t_space) + sum_price_vec_days\n",
    "    price_curve = np.reshape(price_curve, (num_sample,N+1)) \n",
    "    \n",
    "    # Compute the loss as well as the gradient\n",
    "    loss, grad = compute_grad((price_curve,dG_t,battery_0,max_battery), model)\n",
    "    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "    \n",
    "    # Get current Y_0 \\approx u(0,x)\n",
    "#     print(simulate_Y((price,dG_t,battery_0,max_battery), model))\n",
    "    y = simulate_Y((price_curve[:1,:],dG_t,battery_0,max_battery), model).numpy()[0][0] # It should give the final cost. We are not storing the final cost.\n",
    "\n",
    "    currtime = time() - t0\n",
    "\n",
    "    hentry = (i+1, loss.numpy(), y, currtime, lr)\n",
    "#     print(hentry)\n",
    "    history.append(hentry)\n",
    "    if (i+1)%10 == 0:\n",
    "        print('{:5d}   {:12.4f}   {:8.4f}   | {:6.1f}  {:6.2e}'.format(*hentry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-aJYLbLy2ik"
   },
   "source": [
    "Plot training history and evolution of approximation of $C_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "EY4ZQcCDy3EL",
    "outputId": "7e9704ed-1e67-42c7-ad85-4b3c79101b58"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(15,6))\n",
    "xrange = range(len(history))\n",
    "#ax[0].semilogy(xrange, [e[1] for e in history],'k-')  #  [e[1] for e in history] contains the loss function\n",
    "ax[0].plot(xrange, [e[1] for e in history]) \n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_ylabel('training loss')\n",
    "ax[1].plot(xrange, [e[2] for e in history])    #  [e[2] for e in history] contains the final cost y\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].set_ylabel('$C_T$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "8CP3PwcczOvh",
    "outputId": "da1dbc2b-a800-4290-8370-5b12c028a690"
   },
   "outputs": [],
   "source": [
    "# price = simOU(p0_vec,t_space,noise(num_sample, N, dt)) + cyclical(t_space,10.,0.3,0.5)\n",
    "#price = simOU(p0_vec,t_space,noise(num_sample, N, dt))\n",
    "\n",
    "price_vec = simOU(p0_vec,t_space,muOU_vec,sigmaOU_vec,thetaOU_vec,noise(2, N, k, dt))\n",
    "sum_price_vec_days= np.sum(price_vec, axis=1)\n",
    "price_curve = f(t_space) + sum_price_vec_days\n",
    "price_curve = np.reshape(price_curve, (2,N+1))\n",
    "out = simulate_Y((price_curve,dG_t,battery_0,max_battery), model, True)\n",
    "\n",
    "\n",
    "#price_vec1 = simOU(p0_vec_new,t_space,muOU_vec,sigmaOU_vec,thetaOU_vec,noise(num_sample, N, dt)) # (5, 101) 5 days\n",
    "#sum_price_vec_days1= np.sum(price_vec1, axis=1)\n",
    "#price_curve1 = f(t_space) + sum_price_vec_days1\n",
    "#price_curve1 = np.reshape(price_curve1, (N+1,1)) \n",
    "#out = simulate_Y((price_curve1,dG_t,battery_0,max_battery), model, True)\n",
    "\n",
    "bat = out[1]\n",
    "pri = out[2]+price_shift\n",
    "gri = out[3]\n",
    "obj = out[4]+np.cumsum(gri)*price_shift\n",
    "\n",
    "# price = simOU(p0_vec,t_space,noise(num_sample, N, dt)) + cyclical(t_space,10.,0.3,0.5)\n",
    "# price = simOU(p0_vec,t_space,noise(num_sample, N, dt))\n",
    "#price_vec2 = simOU(p0_vec_new,t_space,muOU_vec,sigmaOU_vec,thetaOU_vec,noise(num_sample, N, dt)) # (5, 101) 5 days\n",
    "#sum_price_vec_days2= np.sum(price_vec2, axis=0)\n",
    "#price_curve2 = f(t_space) + sum_price_vec_days2\n",
    "#price_curve2 = np.reshape(price_curve2, (N+1,1)) \n",
    "#out = simulate_Y((price_curve2,dG_t,battery_0,max_battery), model, True)\n",
    "\n",
    "price_vec = simOU(p0_vec,t_space,muOU_vec,sigmaOU_vec,thetaOU_vec,noise(1, N, k, dt))# (5, 101) 5 days\n",
    "sum_price_vec_days= np.sum(price_vec, axis=1)\n",
    "price_curve = f(t_space) + sum_price_vec_days\n",
    "price_curve = np.reshape(price_curve, (1,N+1))\n",
    "out = simulate_Y((price_curve,dG_t,battery_0,max_battery), model, True)\n",
    "\n",
    "bat2 = out[1]\n",
    "pri2 = out[2]+price_shift\n",
    "gri2 = out[3]\n",
    "obj2 = out[4]+np.cumsum(gri2)*price_shift\n",
    "\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(t_space,bat,t_space,bat2)\n",
    "plt.title(\"Battery Level\")\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(t_space,pri,t_space,pri2)\n",
    "plt.title(\"Price\")\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(t_space,gri,t_space,gri2)\n",
    "plt.title(\"Grid Supply\")\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(t_space,obj,t_space,obj2)\n",
    "plt.title(\"Value function\");\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"7DayTrainedBehaviour.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nu3Wa2HlzRUn"
   },
   "source": [
    "Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "EWVm8WfZzUKF",
    "outputId": "e07963c4-fd13-44b3-a3aa-add7752f7a99"
   },
   "outputs": [],
   "source": [
    "t1 = int(N/T*2.)\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(t_space[:t1],bat[:t1],t_space[:t1],bat2[:t1])\n",
    "plt.title(\"Battery Level\")\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(t_space[:t1],pri[:t1],t_space[:t1],pri2[:t1])\n",
    "plt.title(\"Price\")\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(t_space[:t1],gri[:t1],t_space[:t1],gri2[:t1])\n",
    "plt.title(\"Grid Supply\")\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(t_space[:t1],obj[:t1],t_space[:t1],obj2[:t1])\n",
    "plt.title(\"Cumulative Profit\");\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"2DayTrainedBehaviour.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCcVz61Tzcmt"
   },
   "source": [
    "Comparing the value function with and without battery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "_NVDnnizzgJW",
    "outputId": "c6ab6ef8-eb2e-4d2d-b75e-d1c447e60080"
   },
   "outputs": [],
   "source": [
    "plt.plot(t_space,obj,t_space,np.cumsum(dG_t*pri), t_space,obj2, t_space,np.cumsum(dG_t*pri2))\n",
    "#plt.plot(t_space,np.cumsum(dG_t*pri),t_space,np.cumsum(dG_t*pri2))\n",
    "plt.title(\"Total profit over time\");\n",
    "plt.legend([\"With Battery_1\",\"No Battery_1\", \"With Battery_2\", \"No Battery_2\"])\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Nominal Profit\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"TrainedVsUntrained.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WAuN8JnfS6x"
   },
   "source": [
    "Training for different values of the battery maximum capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnRBUcaMMMAW",
    "outputId": "632c0842-979f-4bdc-8854-c1f628912c94"
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "#num_epochs = 40000\n",
    "#num_epochs = 2000\n",
    "#num_epochs = 400\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "#battery_0 = 10\n",
    "battery_0 = 0\n",
    "#max_battery_vec = [0,5,10,15,20,25,30,35,40]\n",
    "max_battery_vec = np.linspace(0.,200.,7)\n",
    "\n",
    "# p0_vec = np.reshape(p0_vec, (5,1))\n",
    "# #p0_vec_new = p0_vec*np.ones((1,num_sample))\n",
    "# #p0_vec = np.array([0.1, 0.2, 0.4, 0.5, 0.7])\n",
    "# #p0_vec = np.reshape(p0_vec,(5,1))\n",
    "# k=np.size(p0_vec)\n",
    "expected_profits=np.zeros(np.size(max_battery_vec))\n",
    "expected_profits_no_battery=np.zeros(np.size(max_battery_vec))\n",
    "\n",
    "for j in range(len(max_battery_vec)):\n",
    "    # Initialize header of output\n",
    "    print('----------------------------------------------------')\n",
    "    print('Iteration: {:5d}/{:5d}'.format(j+1,len(max_battery_vec)))\n",
    "    print('----------------------------------------------------')\n",
    "    print('  Iter          Loss          y   |   Time  Stepsize')\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "    \n",
    "        # Each epoch we draw a batch of random paths\n",
    "        #price = simOU(p0_vec,t_space,noise(num_sample, N, dt)) + cyclical(t_space,10.,0.3,0.5)\n",
    "        #price = (p0_vec_new,t_space,muOU_vec,sigmaOU_vec,thetaOU_vec,dW)\n",
    "        price_vec = simOU(p0_vec,t_space,muOU_vec,sigmaOU_vec,thetaOU_vec,noise(num_sample, N, k, dt))# (5, 101) 5 days\n",
    "        sum_price_vec_days= np.sum(price_vec, axis=1)\n",
    "        price_curve = f(t_space) + sum_price_vec_days\n",
    "        price_curve = np.reshape(price_curve, (num_sample,N+1)) \n",
    "\n",
    "        # Compute the loss as well as the gradient\n",
    "        loss, grad = compute_grad((price_curve,dG_t,battery_0,max_battery_vec[j]), model)\n",
    "        optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "\n",
    "        # Get current Y_0 \\approx u(0,x)\n",
    "    #     print(simulate_Y((price,dG_t,battery_0,max_battery), model))\n",
    "        y = simulate_Y((price_curve,dG_t,battery_0,max_battery_vec[j]), model).numpy() # It should give the final cost. We are not storing the final cost.\n",
    "\n",
    "        z = np.sum(price_curve*dG_t,axis=1)\n",
    "        \n",
    "        currtime = time() - t0\n",
    "\n",
    "        hentry = (i+1, loss.numpy(), np.mean(y), currtime, lr)\n",
    "    #     print(hentry)\n",
    "        history.append(hentry)\n",
    "        if (i+1)%10 == 0:\n",
    "            print('{:5d}   {:12.4f}   {:8.4f}   | {:6.1f}  {:6.2e}'.format(*hentry))\n",
    "    expected_profits[j] = np.mean(y)\n",
    "    expected_profits_no_battery[j] = np.mean(z)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFWvtd6KA7mI"
   },
   "source": [
    "Plotting the expected profit for different maximum battery levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "aujmVzliZToR",
    "outputId": "250b96e0-0f4e-4c26-ab5a-c69eb49cb6df"
   },
   "outputs": [],
   "source": [
    "excess_profit = expected_profits-expected_profits_no_battery\n",
    "plt.plot(max_battery_vec, excess_profit,'b^')\n",
    "# plt.plot(max_battery_vec, expected_profits,'--')\n",
    "A_lr = np.vstack([max_battery_vec,np.ones(len(max_battery_vec))]).T\n",
    "m_lr, c_lr = np.linalg.lstsq(A_lr,excess_profit, rcond=None)[0]\n",
    "\n",
    "plt.plot(max_battery_vec,m_lr*np.array(max_battery_vec) + c_lr,'r--')\n",
    "\n",
    "plt.xlabel(\"Maximum battery levels\")\n",
    "plt.ylabel(\"Expected Excess Profit\");\n",
    "plt.title(\"Best-fit line of expected excess profit for given battery size\")\n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig(\"MeanBatteryVsExcessProfit.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_battery_vec, expected_profits,'b^')\n",
    "# plt.plot(max_battery_vec, expected_profits,'--')\n",
    "A_lr = np.vstack([max_battery_vec,np.ones(len(max_battery_vec))]).T\n",
    "m_lr, c_lr = np.linalg.lstsq(A_lr,expected_profits, rcond=None)[0]\n",
    "\n",
    "plt.plot(max_battery_vec,m_lr*np.array(max_battery_vec) + c_lr,'r--')\n",
    "\n",
    "plt.xlabel(\"Maximum battery levels\")\n",
    "plt.ylabel(\"Expected Profit\");\n",
    "plt.title(\"Best-fit line of expected profit for given battery size\")\n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig(\"MeanBatteryVsProfit.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z,y,'*',z,z,':')\n",
    "\n",
    "plt.xlabel(\"Value with no battery\")\n",
    "plt.ylabel(\"Value with battery\")\n",
    "plt.title(\"Simulation profit with battery vs no battery\");\n",
    "\n",
    "plt.tight_layout();\n",
    "\n",
    "\n",
    "plt.savefig(\"BatteryProfit.png\");\n",
    "\n",
    "print(\"Mean value with battery: \", np.mean(y))\n",
    "print(\"Mean value without battery: \", np.mean(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
